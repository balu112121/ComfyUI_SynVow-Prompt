import json
import urllib.request
import urllib.error
import ssl
import base64
import io
import os
import numpy as np
from PIL import Image

# è·å–å½“å‰æ¨¡å—ç›®å½•
_CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))

def _load_prompt(filename):
    """ä»å¤–éƒ¨æ–‡ä»¶åŠ è½½ promptï¼Œä¾¿äºç»´æŠ¤å’Œä¿®æ”¹"""
    prompt_file = os.path.join(_CURRENT_DIR, "prompts", filename)
    try:
        with open(prompt_file, "r", encoding="utf-8") as f:
            return f.read().strip()
    except FileNotFoundError:
        print(f"âš ï¸ Prompt file not found: {prompt_file}")
        return None
    except Exception as e:
        print(f"âš ï¸ Error loading prompt file {filename}: {e}")
        return None

def _load_system_prompt():
    """åŠ è½½ä¸» system promptï¼Œå¦‚æœå¤±è´¥åˆ™åŠ è½½é»˜è®¤ prompt"""
    prompt = _load_prompt("system_prompt.txt")
    if prompt is None:
        print("âš ï¸ Falling back to default_prompt.txt")
        prompt = _load_prompt("default_prompt.txt")
    if prompt is None:
        raise FileNotFoundError("No prompt files found in prompts/ directory. Please ensure system_prompt.txt or default_prompt.txt exists.")
    return prompt

class EcommercePromptGenerator:
    def __init__(self):
        pass

    def split_response_to_screens(self, text, prompt_count):
        if text is None:
            return []

        s = str(text).replace("\r\n", "\n").replace("\r", "\n").strip()
        if not s:
            return []

        if prompt_count is None or int(prompt_count) <= 1:
            return [s]

        import re

        json_obj_pattern = r'\{\s*"prompt"\s*:\s*"'
        matches = list(re.finditer(json_obj_pattern, s))
        if len(matches) >= 2:
            parsed_objects = []
            idxs = [m.start() for m in matches]
            for i, start_idx in enumerate(idxs):
                end_idx = idxs[i + 1] if i + 1 < len(idxs) else len(s)
                chunk = s[start_idx:end_idx].strip().rstrip(',')
                try:
                    obj = json.loads(chunk)
                    if isinstance(obj, dict) and "prompt" in obj:
                        parsed_objects.append(obj["prompt"])
                    else:
                        parsed_objects.append(chunk)
                except json.JSONDecodeError:
                    clean = re.sub(r'^\s*\{\s*"prompt"\s*:\s*"', '', chunk)
                    clean = re.sub(r'"\s*\}\s*$', '', clean)
                    parsed_objects.append(clean)
            if parsed_objects:
                return parsed_objects

        start_markers = [
            r"(?m)^\s*å±å¹•å®šä½\s*ï¼š",
            r"(?m)^\s*Screen Role\s*:",
            r"(?m)^\s*Main Title\s*:",
            r"(?m)^\s*ä¸»æ ‡é¢˜\s*ï¼š",
        ]
        for pat in start_markers:
            matches = list(re.finditer(pat, s))
            if len(matches) >= 2:
                idxs = [m.start() for m in matches] + [len(s)]
                parts = [s[idxs[i]:idxs[i + 1]].strip() for i in range(len(idxs) - 1)]
                parts = [p for p in parts if p]
                if parts:
                    return parts

        if "\n---\n" in s:
            parts = [p.strip() for p in s.split("\n---\n")]
            parts = [p for p in parts if p]
            if parts:
                return parts

        parts = [p.strip() for p in re.split(r"\n\s*\n\s*\n+", s)]
        parts = [p for p in parts if p]
        if len(parts) >= 2:
            return parts

        return [s]

    def _clean_code_fences(self, response_text):
        cleaned = (response_text or "").strip()
        if cleaned.startswith("```json"):
            cleaned = cleaned[7:]
        if cleaned.startswith("```"):
            cleaned = cleaned[3:]
        if cleaned.endswith("```"):
            cleaned = cleaned[:-3]
        return cleaned.strip()

    def _parse_response_to_prompts_list(self, response_text, expected_count):
        method = "json"
        prompts_list = []
        try:
            cleaned = self._clean_code_fences(response_text)
            prompts_list = json.loads(cleaned)
            if not isinstance(prompts_list, list):
                method = "split:not_list"
                prompts_list = self.split_response_to_screens(response_text, expected_count)
        except json.JSONDecodeError:
            method = "split:json_decode_error"
            prompts_list = self.split_response_to_screens(response_text, expected_count)
        except Exception:
            method = "split:exception"
            prompts_list = self.split_response_to_screens(response_text, expected_count)

        normalized = []
        for item in prompts_list if isinstance(prompts_list, list) else [prompts_list]:
            text = self.extract_prompt_text(item)
            if text is None:
                continue
            normalized.append(self._strip_screen_role_header(text))

        if normalized:
            prompts_list = normalized
        else:
            prompts_list = []

        prompts_list = self.enforce_prompt_count(prompts_list, expected_count, response_text)
        if len(prompts_list) > expected_count:
            prompts_list = prompts_list[:expected_count]

        return prompts_list, method

    def _strip_screen_role_header(self, prompt_text):
        if not isinstance(prompt_text, str):
            return prompt_text

        s = prompt_text.replace("\r\n", "\n").replace("\r", "\n")
        import re

        m0 = re.search(r"(?m)^\s*(Main Copy\s*:|ä¸»æ–‡æ¡ˆ\s*ï¼š|ä¸»æ–‡æ¡ˆ\s*:)", s)
        if m0:
            return s[m0.start():].lstrip()

        m = re.search(r"(?m)^\s*(Main Title\s*:|ä¸»æ ‡é¢˜\s*ï¼š)", s)
        if m:
            return s[m.start():].lstrip()

        m2 = re.search(r"(?m)^\s*(Screen Role\s*:|å±å¹•å®šä½\s*ï¼š)", s)
        if m2:
            after = s[m2.end():]
            after = re.sub(r"^\s*\n", "", after)
            return after.lstrip()

        return s.strip()

    def _is_prompt_structurally_complete(self, prompt_text):
        if not isinstance(prompt_text, str):
            return False
        s = prompt_text.strip()
        if not s:
            return False

        has_main = ("ä¸»æ–‡æ¡ˆ" in s) or ("Main Copy" in s) or ("Main Title" in s) or ("ä¸»æ ‡é¢˜" in s)
        has_sub = ("å‰¯æ–‡æ¡ˆ" in s) or ("SubTitle" in s) or ("Subtitle" in s) or ("å‰¯æ ‡é¢˜" in s)

        return has_main and has_sub

    def enforce_prompt_count(self, prompts_list, prompt_count, raw_response):
        try:
            pc = int(prompt_count)
        except Exception:
            pc = None

        if not pc or pc <= 0:
            return prompts_list

        if not prompts_list:
            return [str(raw_response)]

        if len(prompts_list) == pc:
            return prompts_list

        if len(prompts_list) > pc:
            head = prompts_list[:pc - 1]
            tail = prompts_list[pc - 1:]
            merged_tail = "\n\n".join([t for t in tail if isinstance(t, str) and t.strip()] or [str(t) for t in tail])
            head.append(merged_tail)
            return head

        if len(prompts_list) == 1 and isinstance(prompts_list[0], str):
            parts = self.split_response_to_screens(prompts_list[0], pc)
            if parts and len(parts) >= pc:
                head = parts[:pc - 1]
                tail = parts[pc - 1:]
                head.append("\n\n".join(tail).strip())
                return head

        parts = self.split_response_to_screens(raw_response, pc)
        if parts and len(parts) >= pc:
            head = parts[:pc - 1]
            tail = parts[pc - 1:]
            head.append("\n\n".join(tail).strip())
            return head

        return prompts_list

    def extract_prompt_text(self, item):
        if item is None:
            return None

        if isinstance(item, dict):
            prompt = item.get("prompt")
            if isinstance(prompt, str):
                return prompt
            return json.dumps(item, ensure_ascii=False)

        if isinstance(item, str):
            s = item.strip()
            if (s.startswith("{") and s.endswith("}")) or (s.startswith("[{") and s.endswith("}]") ):
                try:
                    obj = json.loads(s)
                    if isinstance(obj, dict) and isinstance(obj.get("prompt"), str):
                        return obj["prompt"]
                except Exception:
                    pass

            return s.replace("\\n", "\n")

        return str(item)

    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "api_url": ("STRING", {
                    "multiline": False, 
                    "default": "https://api.openai.com/v1",
                }),
                "api_key": ("STRING", {
                    "multiline": False, 
                    "default": "", 
                    "placeholder": "sk-..."
                }),
                "model_name": ("STRING", {
                    "multiline": False, 
                    "default": "gemini-2.0-flash-exp",
                }),

                "product_type": ("STRING", {
                    "multiline": False,
                    "default": "ç¾å¦†ç²‰åº•æ¶²",
                }),
                "selling_points": ("STRING", {
                    "multiline": True,
                    "default": "æŒä¹…æ˜¾è‰²ã€è‡ªåŠ¨é¿éšœ",
                }),
                "design_style": (
                    [
                        "ç®€çº¦ Ins é£",
                        "é«˜çº§å¥¢å",
                        "ç§‘æŠ€æ„Ÿ",
                        "æ¸…æ–°è‡ªç„¶",
                        "å›½æ½®é£",
                        "æ´»æ³¼æ’è‰²",
                        "æç®€å·¥ä¸šé£",
                        "æ¢¦å¹»å”¯ç¾",
                        "äºšé©¬é€Šé£æ ¼",
                    ],
                    {"default": "ç®€çº¦ Ins é£"}
                ),
                "scene_preference": (
                    [
                        "æ··åˆï¼ˆä»¥ä½¿ç”¨åœºæ™¯ä¸ºä¸»ï¼‰",
                        "ç”Ÿæ´»æ–¹å¼ä½¿ç”¨åœºæ™¯ï¼ˆäººç‰©/æ‰‹éƒ¨äº¤äº’ï¼‰",
                        "æ£šæ‹å¹²å‡€èƒŒæ™¯ï¼ˆä¸å¤åˆ»å‚è€ƒå›¾èƒŒæ™¯ï¼‰",
                    ],
                    {"default": "æ··åˆï¼ˆä»¥ä½¿ç”¨åœºæ™¯ä¸ºä¸»ï¼‰"}
                ),
                "output_language": (
                    [
                        "ä¸­æ–‡ (Chinese)",
                        "English",
                        "è‡ªåŠ¨æ£€æµ‹ (Auto)",
                    ],
                    {"default": "è‡ªåŠ¨æ£€æµ‹ (Auto)"}
                ),
                "seed": ("INT", {"default": 0, "min": 0, "max": 99999}),
                "prompt_count": ("INT", {"default": 10, "min": 1, "max": 20, "forceInput": False})
            },
            "optional": {
                "product_image": ("IMAGE",),
                "product_image_2": ("IMAGE",),
                "product_image_3": ("IMAGE",),
                "product_image_4": ("IMAGE",),
            }
        }

    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("prompts_list", "debug_info")
    OUTPUT_IS_LIST = (True, False)

    FUNCTION = "generate_prompts_with_vision"
    CATEGORY = "ğŸ›’ E-Commerce AI/Prompting"

    # --- è¾…åŠ©å‡½æ•°ï¼šComfyUI å›¾ç‰‡ è½¬ Base64 ---
    def tensor_to_base64(self, image, index=0):
        # ComfyUI çš„å›¾ç‰‡æ˜¯ Tensor (Batch, H, W, C)
        if image is None:
            return None

        img_tensor = image
        try:
            if hasattr(image, "shape") and len(image.shape) == 4:
                img_tensor = image[index]
        except Exception:
            img_tensor = image

        i = 255. * img_tensor.cpu().numpy()
        img = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))

        # Resize if too large (max 1024x1024) to avoid 500 errors
        max_size = 1024
        if img.width > max_size or img.height > max_size:
            img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)

        buffered = io.BytesIO()
        img.save(buffered, format="JPEG", quality=85) # é™ä½ä¸€ç‚¹è´¨é‡ä»¥å‡å°ä½“ç§¯
        img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
        return f"data:image/jpeg;base64,{img_str}"

    def collect_base64_images(self, images, max_images=6):
        base64_images = []

        if images is None:
            return base64_images

        for img in images:
            if img is None:
                continue

            try:
                if hasattr(img, "shape") and len(img.shape) == 4:
                    batch = int(img.shape[0])
                    for bi in range(batch):
                        if len(base64_images) >= max_images:
                            return base64_images
                        base64_images.append(self.tensor_to_base64(img, bi))
                else:
                    if len(base64_images) >= max_images:
                        return base64_images
                    base64_images.append(self.tensor_to_base64(img, 0))
            except Exception:
                if len(base64_images) >= max_images:
                    return base64_images
                base64_images.append(self.tensor_to_base64(img, 0))

        return [b for b in base64_images if b]

    def call_llm_vision(self, api_url, api_key, model, system_prompt, user_prompt, base64_images=None, seed=None):
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}",
            "User-Agent": "ComfyUI-NanoPrompt/1.0"
        }

        url = api_url.rstrip('/')
        if url.endswith('/chat'):
            url = f"{url}/completions"
        elif not url.endswith('/chat/completions'):
            url = f"{url}/chat/completions"

        # æ„å»º Vision Payload
        content_list = [{"type": "text", "text": user_prompt}]
        if base64_images:
            if isinstance(base64_images, str):
                base64_images = [base64_images]
            for base64_image in base64_images:
                if not base64_image:
                    continue
                content_list.append({
                    "type": "image_url",
                    "image_url": {
                        "url": base64_image
                    }
                })

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": content_list}
        ]

        payload = {
            "model": model,
            "messages": messages,
            "max_tokens": 4096,
            "temperature": 0.7,
            "stream": False
        }
        
        if seed is not None:
            payload["seed"] = seed

        try:
            print(f"ğŸ”— Calling API: {url}")
            print(f"ğŸ”‘ Using model: {model}")
            
            # ä½¿ç”¨æœªéªŒè¯çš„ SSL ä¸Šä¸‹æ–‡ï¼Œè§£å†³æŸäº›ç¯å¢ƒä¸‹æ‰¾ä¸åˆ°è¯ä¹¦æ–‡ä»¶çš„é—®é¢˜ ([Errno 2] No such file or directory)
            ssl_context = ssl._create_unverified_context()
            
            req = urllib.request.Request(url, data=json.dumps(payload).encode('utf-8'), headers=headers)
            with urllib.request.urlopen(req, timeout=120, context=ssl_context) as response:
                result = json.loads(response.read().decode('utf-8'))
                return {"success": True, "content": result['choices'][0]['message']['content']}
        except urllib.error.HTTPError as e:
            err_body = e.read().decode('utf-8')
            error_msg = f"HTTP Error {e.code}: {err_body}"
            print(f"âŒ {error_msg}")
            return {"success": False, "error": error_msg}
        except urllib.error.URLError as e:
            error_msg = f"URL Error: {str(e)}\nAPI URL: {url}\nReason: {e.reason if hasattr(e, 'reason') else 'Unknown'}"
            print(f"âŒ {error_msg}")
            return {"success": False, "error": error_msg}
        except Exception as e:
            error_msg = f"Error: {str(e)}\nAPI URL: {url}"
            print(f"âŒ {error_msg}")
            return {"success": False, "error": error_msg}

    def generate_prompts_with_vision(self, api_url, api_key, model_name, product_type, selling_points, design_style, scene_preference, output_language, seed, prompt_count, product_image=None, product_image_2=None, product_image_3=None, product_image_4=None):

        base64_images = self.collect_base64_images(
            [product_image, product_image_2, product_image_3, product_image_4],
            max_images=6
        )

        # ä»å¤–éƒ¨æ–‡ä»¶åŠ è½½ system prompt
        system_instruction = _load_system_prompt()
            
        # å¤„ç†è¯­è¨€é€‰æ‹©
        if output_language == "ä¸­æ–‡ (Chinese)":
            lang_instruction = "è¯·ä½¿ç”¨ä¸­æ–‡ç”Ÿæˆæ‰€æœ‰æç¤ºè¯å†…å®¹ï¼ˆåŒ…æ‹¬ä¸»æ–‡æ¡ˆã€å‰¯æ–‡æ¡ˆã€ç”»é¢æè¿°ç­‰ï¼‰ã€‚"
        elif output_language == "English":
            lang_instruction = "Please generate all prompt content in English (including main copy, sub-copy, scene descriptions, etc.)."
        else:
            lang_instruction = "è¯·æ ¹æ®ç”¨æˆ·è¾“å…¥çš„è¯­è¨€è‡ªåŠ¨é€‰æ‹©è¾“å‡ºè¯­è¨€ï¼ˆä¸­æ–‡è¾“å…¥â†’ä¸­æ–‡è¾“å‡ºï¼Œè‹±æ–‡è¾“å…¥â†’è‹±æ–‡è¾“å‡ºï¼‰ã€‚"

        if scene_preference == "ç”Ÿæ´»æ–¹å¼ä½¿ç”¨åœºæ™¯ï¼ˆäººç‰©/æ‰‹éƒ¨äº¤äº’ï¼‰":
            scene_instruction = "æ¯ä¸€å±éƒ½å¿…é¡»æ˜¯å…¨æ–°è®¾è®¡çš„ç”Ÿæ´»æ–¹å¼/ä½¿ç”¨åœºæ™¯ç”»é¢ï¼Œç”»é¢ä¸­å¿…é¡»æœ‰äººç‰©æˆ–æ‰‹éƒ¨ä¸äº§å“äº¤äº’ï¼ˆæ‰‹æŒ/ä½¿ç”¨/ç©¿ç€/æ¶‚æŠ¹/å–·æ´’/æ“ä½œï¼‰ï¼Œå¹¶ä¸”å¿…é¡»æœ‰çœŸå®åœºæ™¯èƒŒæ™¯ï¼ˆæµ´å®¤/æ¢³å¦†å°/å§å®¤/è¡—æ‹/å®¶å±…ç­‰ï¼‰ã€‚ç¡¬æ€§ç¦æ­¢ï¼šç™½åº•æ£šæ‹ã€ç™½åº•å¹³é“ºã€ä¿¯æ‹å¹³é“ºã€è¯ä»¶ç…§å¼æ­£é¢å•†å“å›¾ã€‚"
        elif scene_preference == "æ£šæ‹å¹²å‡€èƒŒæ™¯ï¼ˆä¸å¤åˆ»å‚è€ƒå›¾èƒŒæ™¯ï¼‰":
            scene_instruction = "æ¯ä¸€å±éƒ½å¿…é¡»æ˜¯å…¨æ–°è®¾è®¡çš„æ£šæ‹ç”»é¢ï¼ˆå¹²å‡€èƒŒæ™¯/æ¸å˜/çº¯è‰²/æ‘„å½±æ£šå¸ƒå…‰ï¼‰ï¼Œç¦æ­¢å¤åˆ»å‚è€ƒå›¾çš„åŸèƒŒæ™¯ä¸é“å…·ï¼›å…è®¸å°‘é‡æ‰‹éƒ¨äº¤äº’ç‰¹å†™æ¥è¡¨ç°ä½¿ç”¨ã€‚ç¡¬æ€§ç¦æ­¢ï¼šç™½åº•å¹³é“ºã€ä¿¯æ‹å¹³é“ºã€è¯ä»¶ç…§å¼æ­£é¢å•†å“å›¾ã€‚"
        else:
            scene_instruction = "ä»¥å…¨æ–°è®¾è®¡çš„ä½¿ç”¨åœºæ™¯ä¸ºä¸»ï¼ˆä¼˜å…ˆæœ‰äººç‰©/æ‰‹éƒ¨äº¤äº’ + çœŸå®ç¯å¢ƒèƒŒæ™¯ï¼‰ï¼Œå°‘é‡å±å¹•å¯ç”¨å¹²å‡€æ£šæ‹ç”¨äºå‚æ•°/ç»“æ„è¯´æ˜ï¼›ç¦æ­¢æŠŠå‚è€ƒå›¾èƒŒæ™¯å½“ä½œå¿…é¡»å¤åˆ»çš„åœºæ™¯ã€‚ç¡¬æ€§ç¦æ­¢ï¼šç™½åº•æ£šæ‹ã€ç™½åº•å¹³é“ºã€ä¿¯æ‹å¹³é“ºã€è¯ä»¶ç…§å¼æ­£é¢å•†å“å›¾ã€‚"

        try:
            target_count = int(prompt_count)
        except Exception:
            target_count = 10
        target_count = max(1, min(20, target_count))

        base_user_req = f"""
è¯·ä¸ºä»¥ä¸‹äº§å“è®¾è®¡ {{COUNT}} å±è¯¦æƒ…é¡µæç¤ºè¯ï¼š
1. äº§å“ç±»å‹: {product_type}
2. æ ¸å¿ƒå–ç‚¹: {selling_points}
3. è®¾è®¡é£æ ¼: {design_style}
4. åœºæ™¯åå¥½: {scene_preference}ï¼ˆå¿…é¡»éµå®ˆï¼š{scene_instruction}ï¼‰
5. è¾“å‡ºè¯­è¨€è¦æ±‚: {lang_instruction}

(å¦‚æœé™„å¸¦äº†å›¾ç‰‡ï¼Œè¯·å°†å…¶ä½œä¸ºäº§å“å¤–è§‚å‚è€ƒï¼›è‹¥æœ‰å¤šå¼ å›¾ï¼ŒæŠŠå®ƒä»¬è§†ä¸ºåŒä¸€äº§å“çš„ä¸åŒè§’åº¦/ç»†èŠ‚è¡¥å……ï¼Œå¹¶åœ¨æ‰€æœ‰å±ä¿æŒå¤–è§‚ä¸€è‡´)
å‚è€ƒå›¾æ•°é‡: {len(base64_images)}
å‚è€ƒå›¾ç¼–å·: å›¾ç‰‡1=product_image, å›¾ç‰‡2=product_image_2, å›¾ç‰‡3=product_image_3, å›¾ç‰‡4=product_image_4ï¼ˆè‹¥æŸå¼ æœªæä¾›åˆ™å¿½ç•¥ï¼‰

é‡è¦ï¼šæ¯å±è¾“å‡ºåªåŒ…å«æç¤ºè¯æ­£æ–‡ï¼Œä¸è¦å‡ºç°å­—æ®µåï¼ˆä¾‹å¦‚ promptã€consistency_idï¼‰ï¼Œä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæ–‡å­—ã€‚

é‡è¦ï¼šå‚è€ƒå›¾åªç”¨äºé”å®šäº§å“/äººç‰©å¤–è§‚ï¼ˆå½¢çŠ¶/é¢œè‰²/æè´¨/logo/ç»†èŠ‚ï¼‰ã€‚å¿…é¡»æŠ å‡ºä¸»ä½“ã€å¿½ç•¥åŸå›¾èƒŒæ™¯ï¼Œé‡å»ºæ–°çš„åœºæ™¯ä¸é•œå¤´ã€‚
åœºæ™¯ç”Ÿæˆç¤ºä¾‹ï¼ˆä½ éœ€è¦æ ¹æ®äº§å“ç±»å‹è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„ä¸€ç±»æˆ–ç»„åˆï¼‰ï¼š
- å¹é£æœº/ç”µå™¨ï¼šç¾å¥³æˆ–æ¨¡ç‰¹æ‰‹æŒäº§å“æ­£åœ¨ä½¿ç”¨ï¼ˆå¹å¤´å‘/æ“ä½œï¼‰ï¼Œæœ‰çœŸå®ç”Ÿæ´»æ–¹å¼ç¯å¢ƒï¼ˆæµ´å®¤/æ¢³å¦†å°/å§å®¤ï¼‰ä¸åŠ¨æ„Ÿå‘ä¸ã€‚
- è¡£æœï¼šæ¨¡ç‰¹ç©¿ä¸Šè¯¥è¡£æœçš„ä¸Šèº«/å…¨èº«å±•ç¤ºï¼Œæ­é…ç¬¦åˆé£æ ¼çš„ç¯å¢ƒï¼ˆè¡—æ‹/å®¤å†…å½±æ£š/ç”Ÿæ´»æ–¹å¼ï¼‰ï¼Œä½†è¡£æœç‰ˆå‹ä¸ç»†èŠ‚å¿…é¡»ä¸¥æ ¼ä¸€è‡´ã€‚
- æ²æµ´éœ²/æ´—é¢å¥¶ï¼šè¿‘è·ç¦»ä½¿ç”¨ç‰¹å†™ï¼ˆæŒ¤å‹/èµ·æ³¡/æ¶‚æŠ¹/æ°´ç ï¼‰ï¼Œå¼ºè°ƒè´¨æ„Ÿä¸ä½¿ç”¨ä½“éªŒã€‚

è¯·ä¸¥æ ¼è¾“å‡º JSON å­—ç¬¦ä¸²åˆ—è¡¨ (List[str])ï¼Œåˆ—è¡¨é•¿åº¦å¿…é¡»ä¸¥æ ¼ç­‰äº {{COUNT}}ã€‚
æ¯ä¸ªå…ƒç´ å¯¹åº”ä¸€å±ï¼ˆä¸€ä¸ªå­—ç¬¦ä¸²=ä¸€å±å®Œæ•´æç¤ºè¯æ­£æ–‡ï¼‰ï¼Œå­—ç¬¦ä¸²å†…éƒ¨å…è®¸æ¢è¡Œã€‚
æ¯ä¸ªå…ƒç´ çš„æ­£æ–‡å¿…é¡»ç›´æ¥ä»â€œä¸»æ–‡æ¡ˆï¼š/Main Copy:â€å¼€å§‹ï¼ˆæˆ–ä»â€œä¸»æ ‡é¢˜ï¼š/Main Title:â€å¼€å§‹ï¼‰ï¼Œä¸è¦åœ¨å¼€å¤´è¾“å‡ºä»»ä½•â€œå±å¹•å®šä½/Screen Roleâ€æˆ–â€œé¦–å±/æ¬¡å±/å–ç‚¹æ€»è§ˆ/æ ¸å¿ƒæœºç†â€ç­‰å±å¹•æ ‡é¢˜è¡Œã€‚
ä¸è¦è¾“å‡º Markdownã€ä¸è¦ä»£ç å—ã€ä¸è¦è¾“å‡ºä»»ä½•é¢å¤–è§£é‡Šã€‚
"""

        collected = []
        raw_responses = []
        attempts = []
        max_per_call = 6
        max_calls = 10
        call_idx = 0
        last_error = None

        while len(collected) < target_count and call_idx < max_calls:
            remaining = target_count - len(collected)
            request_n = remaining if remaining <= max_per_call else max_per_call

            user_req = base_user_req.replace("{COUNT}", str(request_n))
            if len(collected) > 0:
                user_req += f"\n\nè¡¥å……è¦æ±‚ï¼šè¿™æ˜¯ç»­å†™ç”Ÿæˆã€‚è¯·ç”Ÿæˆæ–°çš„ {request_n} å±ï¼Œä¸è¦é‡å¤ä¹‹å‰çš„å†…å®¹ä¸è§’åº¦ã€‚"

            print(f"ğŸ¨ Generating {request_n} screen prompts... ({len(collected)}/{target_count})")
            result = self.call_llm_vision(api_url, api_key, model_name, system_instruction, user_req, base64_images if base64_images else None, seed)
            call_idx += 1

            if not result["success"]:
                last_error = result.get("error")
                attempts.append({
                    "call": call_idx,
                    "requested": request_n,
                    "parsed": 0,
                    "accepted": 0,
                    "method": "api_error",
                    "error": last_error,
                })
                continue

            response = result.get("content", "")
            raw_responses.append(response)

            batch_prompts, method = self._parse_response_to_prompts_list(response, request_n)

            accepted = []
            rejected = 0
            for p in batch_prompts:
                if self._is_prompt_structurally_complete(p):
                    accepted.append(p)
                else:
                    rejected += 1

            if not accepted and batch_prompts:
                accepted = batch_prompts

            if len(accepted) > request_n:
                accepted = accepted[:request_n]

            collected.extend(accepted)

            attempts.append({
                "call": call_idx,
                "requested": request_n,
                "parsed": len(batch_prompts),
                "accepted": len(accepted),
                "rejected": rejected,
                "method": method,
                "response_chars": len(response) if isinstance(response, str) else None,
            })

        if len(collected) > target_count:
            collected = collected[:target_count]

        if len(collected) < target_count:
            missing = target_count - len(collected)
            msg = "[GENERATION_FAILED] Unable to generate enough prompts."
            if last_error:
                msg = f"[GENERATION_FAILED] {last_error}"
            collected.extend([msg] * missing)

        debug_payload = {
            "input_summary": base_user_req.replace("{COUNT}", str(target_count)),
            "reference_image_count": len(base64_images),
            "attempts": attempts,
        }
        if raw_responses:
            debug_payload["raw_response"] = raw_responses[-1]
        if last_error:
            debug_payload["error"] = last_error

        return (collected, json.dumps(debug_payload, ensure_ascii=False))


class ListToBatchConverter:
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "prompts_list": ("STRING", {
                    "forceInput": True,
                    "multiline": True,
                    "placeholder": "è¾“å…¥æç¤ºè¯åˆ—è¡¨ï¼Œæ¯è¡Œä¸€ä¸ª"
                }),
                "batch_size": ("INT", {
                    "default": 5,
                    "min": 1,
                    "max": 20,
                    "forceInput": False,
                    "tooltip": "æ¯æ‰¹å¤„ç†çš„æ•°é‡"
                }),
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("batch_output",)
    OUTPUT_IS_LIST = (False,)

    FUNCTION = "convert_list_to_batches"
    CATEGORY = "ğŸ›’ E-Commerce AI/Prompting"

    def convert_list_to_batches(self, prompts_list, batch_size):
        if not prompts_list or not prompts_list.strip():
            return ("Error: No prompts list provided",)
        
        try:
            # è§£æJSONæ ¼å¼çš„åˆ—è¡¨
            if prompts_list.strip().startswith('['):
                # å°è¯•è§£æJSONåˆ—è¡¨
                try:
                    prompts = json.loads(prompts_list)
                    if isinstance(prompts, list):
                        # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå–æ‰€æœ‰å…ƒç´ 
                        prompt_items = prompts
                    else:
                        # å¦‚æœæ˜¯å…¶ä»–ç±»å‹ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²åˆ—è¡¨
                        prompt_items = [str(prompts)]
                except json.JSONDecodeError:
                    # JSONè§£æå¤±è´¥ï¼ŒæŒ‰è¡Œåˆ†å‰²
                    prompt_items = [line.strip() for line in prompts_list.split('\n') if line.strip()]
            else:
                # æŒ‰è¡Œåˆ†å‰²
                prompt_items = [line.strip() for line in prompts_list.split('\n') if line.strip()]
            
            if not prompt_items:
                return ("Error: No valid prompts found",)
            
            # æŒ‰æ‰¹æ¬¡å¤§å°åˆ†ç»„
            batches = []
            for i in range(0, len(prompt_items), batch_size):
                batch = prompt_items[i:i + batch_size]
                batches.append('\n'.join(batch))
            
            # å°†æ‰€æœ‰æ‰¹æ¬¡åˆå¹¶ä¸ºä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œç”¨---åˆ†éš”ä¸åŒæ‰¹æ¬¡
            result = ""
            for i, batch in enumerate(batches):
                if i > 0:
                    result += "\n---\n"
                result += batch
            
            return (result,)
            
        except Exception as e:
            return (f"Error: {str(e)}",)


NODE_CLASS_MAPPINGS = {
    "EcommercePromptGenerator": EcommercePromptGenerator,
    "ListToBatchConverter": ListToBatchConverter
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "EcommercePromptGenerator": "ğŸ›’ E-Commerce Prompt Generator (Gemini)",
    "ListToBatchConverter": "ğŸ”„ List to Batch Converter"
}
